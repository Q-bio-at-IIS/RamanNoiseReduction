{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cca269f",
   "metadata": {},
   "source": [
    "# Transcriptomic profile estimation with various sample size datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e39d641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy import io\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../scripts\")\n",
    "from noiseReductionMethodology import preprocessing, Raman_model\n",
    "from analysis_pclda import LDA_model\n",
    "from predictFunc import calcPrediction\n",
    "from util import returnValues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91603e",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "339219f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>590</th>\n",
       "      <th>591</th>\n",
       "      <th>592</th>\n",
       "      <th>593</th>\n",
       "      <th>594</th>\n",
       "      <th>595</th>\n",
       "      <th>596</th>\n",
       "      <th>597</th>\n",
       "      <th>598</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.777427</td>\n",
       "      <td>0.798224</td>\n",
       "      <td>0.788404</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>0.758397</td>\n",
       "      <td>0.730189</td>\n",
       "      <td>0.688064</td>\n",
       "      <td>0.620933</td>\n",
       "      <td>0.629037</td>\n",
       "      <td>0.658134</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.786467</td>\n",
       "      <td>-1.778755</td>\n",
       "      <td>-1.773075</td>\n",
       "      <td>-1.801913</td>\n",
       "      <td>-1.817556</td>\n",
       "      <td>-1.802574</td>\n",
       "      <td>-1.790176</td>\n",
       "      <td>-1.800517</td>\n",
       "      <td>-1.835198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.819071</td>\n",
       "      <td>0.838680</td>\n",
       "      <td>0.801314</td>\n",
       "      <td>0.734114</td>\n",
       "      <td>0.704192</td>\n",
       "      <td>0.677671</td>\n",
       "      <td>0.615264</td>\n",
       "      <td>0.532932</td>\n",
       "      <td>0.525684</td>\n",
       "      <td>0.557399</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.942792</td>\n",
       "      <td>-1.988656</td>\n",
       "      <td>-2.001273</td>\n",
       "      <td>-2.014088</td>\n",
       "      <td>-2.021082</td>\n",
       "      <td>-2.015529</td>\n",
       "      <td>-1.991117</td>\n",
       "      <td>-1.972676</td>\n",
       "      <td>-1.962001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.784357</td>\n",
       "      <td>0.799093</td>\n",
       "      <td>0.757752</td>\n",
       "      <td>0.689691</td>\n",
       "      <td>0.634893</td>\n",
       "      <td>0.599651</td>\n",
       "      <td>0.571955</td>\n",
       "      <td>0.523794</td>\n",
       "      <td>0.562298</td>\n",
       "      <td>0.624879</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.856136</td>\n",
       "      <td>-1.828801</td>\n",
       "      <td>-1.792533</td>\n",
       "      <td>-1.794846</td>\n",
       "      <td>-1.801112</td>\n",
       "      <td>-1.815291</td>\n",
       "      <td>-1.843331</td>\n",
       "      <td>-1.893848</td>\n",
       "      <td>-1.902506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.911177</td>\n",
       "      <td>0.947830</td>\n",
       "      <td>0.915633</td>\n",
       "      <td>0.857712</td>\n",
       "      <td>0.857826</td>\n",
       "      <td>0.800391</td>\n",
       "      <td>0.765022</td>\n",
       "      <td>0.717855</td>\n",
       "      <td>0.708535</td>\n",
       "      <td>0.691836</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.736215</td>\n",
       "      <td>-1.723609</td>\n",
       "      <td>-1.730770</td>\n",
       "      <td>-1.767129</td>\n",
       "      <td>-1.791136</td>\n",
       "      <td>-1.787874</td>\n",
       "      <td>-1.769603</td>\n",
       "      <td>-1.755394</td>\n",
       "      <td>-1.783720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.876973</td>\n",
       "      <td>0.864326</td>\n",
       "      <td>0.801489</td>\n",
       "      <td>0.735828</td>\n",
       "      <td>0.716139</td>\n",
       "      <td>0.703013</td>\n",
       "      <td>0.681590</td>\n",
       "      <td>0.651481</td>\n",
       "      <td>0.649721</td>\n",
       "      <td>0.639855</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.958845</td>\n",
       "      <td>-1.995900</td>\n",
       "      <td>-2.030070</td>\n",
       "      <td>-2.019414</td>\n",
       "      <td>-2.005512</td>\n",
       "      <td>-1.999898</td>\n",
       "      <td>-2.020077</td>\n",
       "      <td>-2.048122</td>\n",
       "      <td>-2.082585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.777427  0.798224  0.788404  0.760493  0.758397  0.730189  0.688064   \n",
       "1  0.819071  0.838680  0.801314  0.734114  0.704192  0.677671  0.615264   \n",
       "2  0.784357  0.799093  0.757752  0.689691  0.634893  0.599651  0.571955   \n",
       "3  0.911177  0.947830  0.915633  0.857712  0.857826  0.800391  0.765022   \n",
       "4  0.876973  0.864326  0.801489  0.735828  0.716139  0.703013  0.681590   \n",
       "\n",
       "          7         8         9  ...       590       591       592       593  \\\n",
       "0  0.620933  0.629037  0.658134  ... -1.786467 -1.778755 -1.773075 -1.801913   \n",
       "1  0.532932  0.525684  0.557399  ... -1.942792 -1.988656 -2.001273 -2.014088   \n",
       "2  0.523794  0.562298  0.624879  ... -1.856136 -1.828801 -1.792533 -1.794846   \n",
       "3  0.717855  0.708535  0.691836  ... -1.736215 -1.723609 -1.730770 -1.767129   \n",
       "4  0.651481  0.649721  0.639855  ... -1.958845 -1.995900 -2.030070 -2.019414   \n",
       "\n",
       "        594       595       596       597       598  label  \n",
       "0 -1.817556 -1.802574 -1.790176 -1.800517 -1.835198      0  \n",
       "1 -2.021082 -2.015529 -1.991117 -1.972676 -1.962001      0  \n",
       "2 -1.801112 -1.815291 -1.843331 -1.893848 -1.902506      0  \n",
       "3 -1.791136 -1.787874 -1.769603 -1.755394 -1.783720      0  \n",
       "4 -2.005512 -1.999898 -2.020077 -2.048122 -2.082585      0  \n",
       "\n",
       "[5 rows x 600 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAMAN = pd.read_csv(\"../../data/RAMAN_FINGERPRINT.csv\")\n",
    "TRANSCRIPTOME = pd.read_csv(\"../../data/TRANSCRIPTOME.csv\")\n",
    "RAMAN_PROCESSED = preprocessing(RAMAN)\n",
    "RAMAN_PROCESSED.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7373ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP = [RAMAN_PROCESSED[RAMAN_PROCESSED[\"label\"] == i].reset_index(drop=True) for i in range(RAMAN_PROCESSED[\"label\"].max() + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b2d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorList = [\"gray\", \"#B51700\"]\n",
    "nameList = [\"PCA\", \"NRM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b8d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "numList = np.arange(6, 60, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4ad2e",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9e2f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataList(n, GROUP=GROUP):\n",
    "    RAMAN_dataList = []\n",
    "    np.random.seed(0)\n",
    "    for j in range(100):\n",
    "        INPUTDATA = pd.DataFrame([])\n",
    "        for OUT in GROUP:\n",
    "            idxList = list(np.arange(OUT.shape[0]))\n",
    "            np.random.shuffle(idxList)\n",
    "            INPUTDATA = pd.concat([INPUTDATA, OUT.iloc[idxList[:n], :]], axis=0)\n",
    "        INPUTDATA = INPUTDATA.reset_index(drop=True)\n",
    "\n",
    "        RAMAN_dataList.append(INPUTDATA)\n",
    "    return RAMAN_dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e00b71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performTranscriptomicProfileEstimation(dataList, cutPercentages):\n",
    "    predict_dataList = []\n",
    "    percent_to_dim_PCA_dataList = []\n",
    "    percent_NRM_dataList = []\n",
    "\n",
    "    for RAMAN_DATA in dataList:\n",
    "        print(\".\", end=\"\")\n",
    "        predict_list = []\n",
    "        percent_to_dim_PCA = []\n",
    "        percent_NRM = []\n",
    "\n",
    "        for cutPercent in cutPercentages:\n",
    "            raman_model = Raman_model(RAMAN_DATA, cutRange=cutPercent, cutMode=\"percent_fixedDim\")\n",
    "            raman_model.calcTransformation()\n",
    "\n",
    "            out = []\n",
    "            for DATA in [raman_model.RAMAN_PCA, raman_model.RAMAN_NRM]:\n",
    "                lda_model = LDA_model()\n",
    "                DATA_LDA = lda_model.fit_transform(DATA)\n",
    "\n",
    "                DATA_LDA = DATA_LDA.groupby(\"label\").mean()\n",
    "                DATA_LDA[\"label\"] = np.arange(DATA_LDA.shape[0])\n",
    "\n",
    "                PREDICT = calcPrediction(TRANSCRIPTOME, DATA_LDA, n_components=0, max_iter=50000)\n",
    "\n",
    "                out.append(PREDICT)\n",
    "\n",
    "            predict_list.append(out)\n",
    "            percent_to_dim_PCA.append(raman_model.k_hat)\n",
    "            percent_NRM.append(raman_model.percent_tilde)\n",
    "\n",
    "        predict_dataList.append(predict_list)\n",
    "        percent_to_dim_PCA_dataList.append(percent_to_dim_PCA)\n",
    "        percent_NRM_dataList.append(percent_NRM)\n",
    "    print(\"\")\n",
    "    return predict_dataList, percent_to_dim_PCA_dataList, percent_NRM_dataList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a030a71",
   "metadata": {},
   "source": [
    "## Perform transcriptomic profile estimation\n",
    "\n",
    "**Note**:  \n",
    "The following cell may take a long time to run, as it performs transcriptomic profile estimation across multiple sample sizes and dimensions.  \n",
    "To save time, the corresponding precomputed results are already included in this repository at:  \n",
    " \n",
    "`results/SUMMARY_PERCENT_fixedDim_SPOMBE_dataSize{n}.csv` (where `{n}` = 6, 12, 18, 24, 30, 36, 42, 48, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256ea9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80. , 80.5, 81. , 81.5, 82. , 82.5, 83. , 83.5, 84. , 84.5, 85. ,\n",
       "       85.5, 86. , 86.5, 87. , 87.5, 88. , 88.5, 89. , 89.5, 90. , 90.5,\n",
       "       91. , 91.5, 92. , 92.5, 93. , 93.5, 94. , 94.5, 95. , 95.5, 96. ,\n",
       "       96.5, 97. , 97.5, 98. , 98.5, 99. , 99.5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutPercentages = np.arange(80, 100, 0.5)\n",
    "cutPercentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493c0693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n =  6] ===================================\n",
      "....................................................................................................\n",
      "============================================\n",
      "[n = 12] ===================================\n",
      "....................................................................................................\n",
      "============================================\n",
      "[n = 18] ===================================\n",
      "....................................................................................................\n",
      "============================================\n",
      "[n = 24] ===================================\n",
      "....................................................................................................\n",
      "============================================\n",
      "[n = 30] ===================================\n",
      "....................................................................................................\n",
      "============================================\n",
      "[n = 36] ===================================\n",
      "....................................................................................................\n",
      "============================================\n",
      "[n = 42] ===================================\n",
      "....................................................................................................\n",
      "============================================\n",
      "[n = 48] ===================================\n",
      "....................................................................................................\n",
      "============================================\n",
      "[n = 54] ===================================\n",
      "....................................................................................................\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "for n in numList:\n",
    "    print(f\"[n = {n:>2}] ===================================\")\n",
    "    dataList = generateDataList(n)\n",
    "    predict_dataList, percent_to_dim_PCA_dataList, percent_NRM_dataList = performTranscriptomicProfileEstimation(dataList, cutPercentages)\n",
    "    \n",
    "    SUMMARY_TABLE = pd.DataFrame(columns=[f\"{i:.1f}%\" for i in cutPercentages]).T\n",
    "    SUMMARY_TABLE[\"dim_PCA\"] = np.mean(percent_to_dim_PCA_dataList, axis=0)\n",
    "    SUMMARY_TABLE[\"dim_PCA_std\"] = np.std(percent_to_dim_PCA_dataList, axis=0)\n",
    "    SUMMARY_TABLE[\"percent_NRM\"] = np.mean(percent_NRM_dataList, axis=0)\n",
    "    SUMMARY_TABLE[\"percent_NRM_std\"] = np.std(percent_NRM_dataList, axis=0)\n",
    "    \n",
    "    out_pca = np.vstack([np.array([np.sum((returnValues(data[0]) - returnValues(TRANSCRIPTOME)) ** 2, axis=1).sum()\n",
    "                               for data in predict_list])\n",
    "                     for predict_list in predict_dataList])\n",
    "\n",
    "    out_nrm = np.vstack([np.array([np.sum((returnValues(data[1]) - returnValues(TRANSCRIPTOME)) ** 2, axis=1).sum()\n",
    "                                   for data in predict_list])\n",
    "                         for predict_list in predict_dataList])\n",
    "\n",
    "    pList = np.array([stats.wilcoxon(a, b, alternative=\"two-sided\").pvalue for a, b in zip(out_pca.T, out_nrm.T)])\n",
    "\n",
    "    SUMMARY_TABLE[\"PRESS_PCA\"] = np.mean(out_pca, axis=0)\n",
    "    SUMMARY_TABLE[\"PRESS_NRM\"] = np.mean(out_nrm, axis=0)\n",
    "    SUMMARY_TABLE[\"PRESS_PCA_std\"] = np.std(out_pca, axis=0)\n",
    "    SUMMARY_TABLE[\"PRESS_NRM_std\"] = np.std(out_nrm, axis=0)\n",
    "    SUMMARY_TABLE[\"PRESS_diff\"] = np.mean(out_nrm - out_pca, axis=0)\n",
    "    SUMMARY_TABLE[\"PRESS_diff_std\"] = np.std(out_nrm - out_pca, axis=0)\n",
    "    SUMMARY_TABLE[\"PRESS_pVal\"] = pList\n",
    "\n",
    "    out_pca_perCon = np.vstack([np.vstack([np.sum((returnValues(predict_list[i][0]) - returnValues(TRANSCRIPTOME)) ** 2, axis=1)\n",
    "                                           for predict_list in predict_dataList]).mean(axis=0)\n",
    "                                for i in range(len(cutPercentages))])\n",
    "\n",
    "    out_nrm_perCon = np.vstack([np.vstack([np.sum((returnValues(predict_list[i][1]) - returnValues(TRANSCRIPTOME)) ** 2, axis=1)\n",
    "                                           for predict_list in predict_dataList]).mean(axis=0)\n",
    "                                for i in range(len(cutPercentages))])\n",
    "\n",
    "\n",
    "    SUMMARY_TABLE.loc[:, [f\"PRESS_PCA_c{i + 1}\" for i in range(len(GROUP))]] = out_pca_perCon\n",
    "    SUMMARY_TABLE.loc[:, [f\"PRESS_NRM_c{i + 1}\" for i in range(len(GROUP))]] = out_nrm_perCon\n",
    "    \n",
    "    \n",
    "    out_pca = np.vstack([np.array([np.hstack([cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))[0]\n",
    "                                              for a, b in zip(returnValues(data[0]), returnValues(TRANSCRIPTOME))]).mean()\n",
    "                                   for data in predict_list])\n",
    "                         for predict_list in predict_dataList])\n",
    "\n",
    "    out_nrm = np.vstack([np.array([np.hstack([cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))[0]\n",
    "                                              for a, b in zip(returnValues(data[1]), returnValues(TRANSCRIPTOME))]).mean()\n",
    "                                   for data in predict_list])\n",
    "                         for predict_list in predict_dataList])\n",
    "\n",
    "    pList = np.array([stats.wilcoxon(a, b, alternative=\"two-sided\").pvalue for a, b in zip(out_pca.T, out_nrm.T)])\n",
    "\n",
    "    SUMMARY_TABLE[\"cosine_PCA\"] = np.mean(out_pca, axis=0)\n",
    "    SUMMARY_TABLE[\"cosine_NRM\"] = np.mean(out_nrm, axis=0)\n",
    "\n",
    "    SUMMARY_TABLE[\"cosine_diff\"] = np.mean(out_nrm - out_pca, axis=0)\n",
    "    SUMMARY_TABLE[\"cosine_diff_std\"] = np.std(out_nrm - out_pca, axis=0)\n",
    "    SUMMARY_TABLE[\"cosine_pVal\"] = pList\n",
    "\n",
    "    SUMMARY_TABLE.to_csv(f\"../../results/SUMMARY_PERCENT_fixedDim_SPOMBE_dataSize{n}.csv\", index=True)\n",
    "    \n",
    "    print(f\"============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9de21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:raman] *",
   "language": "python",
   "name": "conda-env-raman-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
